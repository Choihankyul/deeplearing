{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_computervision_deeplearing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "13RUbjUZUCXKxlgXf2MGJSHD_FXSW6mk8",
      "authorship_tag": "ABX9TyOsykCBqKCIe+nyNbRgUavJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Choihankyul/deeplearing/blob/main/basic_computervision_deeplearing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "        "
      ],
      "metadata": {
        "id": "Tt8oMqnZKqo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 깃허브에 올리기\n",
        "!git clone https://Choihankyul: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@github.com/Choihankyul/deeplearing.git"
      ],
      "metadata": {
        "id": "v6uTGkyzcHHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱 신경망\n",
        "- 컨브넷이 (image_height,image_weight, image_channels) 크기의 입력 텐서를 사용한다는 점이 중요(배치 차원은 포함 하지 않음)"
      ],
      "metadata": {
        "id": "3A12VtKxcBL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 컨브넷 만들기\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape=(28,28,1)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64, (3,3),activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64, (3,3),activation = 'relu'))"
      ],
      "metadata": {
        "id": "W8PHI2LRK4D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 summary 출력\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "bzCDfmmSMUTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컨브넷 위에 분류기 추가하기\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation = 'relu'))\n",
        "model.add(layers.Dense(10, activation = 'softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "OikkB34ENy1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 데이터 확인 및 컨브넷 훈련\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape)\n",
        "print(len(train_labels))"
      ],
      "metadata": {
        "id": "BEWUV_KFOXls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000,28,28,1))\n",
        "train_images = train_images.astype('float32') /255\n",
        "\n",
        "test_images = test_images.reshape((10000,28,28,1))\n",
        "test_image = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "model.compile(optimizer = 'rmsprop',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "model.fit(train_images,train_labels,epochs=5, batch_size = 64)"
      ],
      "metadata": {
        "id": "p3mWgGY9Pntr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss ,test_acc = model.evaluate(test_images, test_labels)\n",
        "test_acc"
      ],
      "metadata": {
        "id": "PLR_L4QPQmO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 합성곱 연산\n",
        "- 완전 연결층과 합성곱 층 사이의 근본적인 차이\n",
        "  - Dense 층은 입력 특성 공간에 있는 전역 패턴(예를 들어 MNIST 숫자 이미지에서 모든 픽셀에 걸친 패턴)을 학습하지만 합성곱 층은 패턴을 학습\n",
        "  - 이미지일 경우 작은 2D 원도우(window)로 입력 배턴을 찾습니다.\n",
        "- ConvNet의 두 가지 흥미로운 성질\n",
        "  - 학습된 패턴은 평행 이동 불변성(translation invariant)를 가집니다\n",
        "    - 컨브넷이 이미지의 오른쪽 아래 모서리에서 어떤 패턴을 학습했다면 다른 곳(예를 들어 왼쪽 위 모서리)에서도 패턴을 인식 할 수 있습니다. 완전 연결 네트워크는 새로운 위치에 나타난 것은 새로운 패턴으로 학습해야 합니다.\n",
        "    - 적은 수의 훈련 샘플을 사용해서 일반화 능력을 가진 표현을 학습할 수 있습니다.\n",
        "  - ConvNet은 패턴의 공간적 계층 구조를 학습할 수 있습니다.\n",
        "    - 첫 번째 합성곱 층이 엣지 같은 작은 지역 패턴을 학습하니다.\n",
        "    - 두 번째 합성곱 층은 첫 번째 층의 특성으로 구성된 더 큰 패터을 학습하는 식입니다.\n",
        "    - 컨브넷은 매우 복잡하고 추상적인 시각전 개념을 효과적으로 학습 할 수 있습니다.\n",
        "    - 근본적으로 우리가 보는 세상은 공간적 계층 구조를 가집니다.\n",
        "\n",
        "- 합성곱 연산은 특성맵(feature map)이라고 부르는 3D 텐서에 적용됩니다.\n",
        "  - 이 텐서는 2개의 공간축(높이와 너비)과 깊이 축(채널)으로 구성 됩니다.\n",
        "- 합성곱 연산은 입력 특성 맵에서 작은 패치들을 추출하고 이런 모든 패치에 같은 변환을 적용하여 출력 특성 맵(output feature map)을 만듭니다.\n",
        "- 출력 특성 맵도 높이와 너비를 가진 3D 텐서입니다.\n",
        "- 출력 텐서의 깊이는 층의 매개변수로 결정되기 때문에 상황에 따라 다릅니다.\n",
        "- 이렇게 되면 깊이의 축의 채널은 더 이상 RGB 입력처럼 특정 컬러를 의미하지 않습니다.\n",
        "- 그 대신 일종의 필터(filter)를 의미합니다. 필터는 입력 데이터의 어떤 특성을 인코딩 해야합니다.ex) '입력에 얼굴이 있는지'\n",
        "- 특성맵 : 깊이 축에 있는 각 차원은 하나의 특성(또는 필터)이고, 2D 텐서 output[:, :, n]은 입력에 대한 이 필터 응답을 나타내는 2D 공간상의 맵이다\n",
        "- 합성곱을 정의하는 2개 파라미터\n",
        "  - 입력으로부터 뽑아낼 패치의 크기\n",
        "    - 전형적으로 3 X 3 또는 5 X 5 크기를 사용\n",
        "  - 특성 맵의 출력 깊이\n",
        "    - 합성곱으로 계산할 필터의 수\n",
        "- 3D 입력 특성맵 위를 3 X 3 또는 5 X 5 크기의 윈도우가 슬라이딩(sliding) 하면서 모든 위치의 특성 패치를 추출하는 방식으로 합성곱이 작동\n",
        "- 출력 높이와 너비는 입력 높이와 너비와 다를 수 있다.그 이유 2가지\n",
        "  - 경계문제, 입력 특성 맵에 패딩을 추가하여 대응할 수 있습니다.\n",
        "    - 5 x 5 특성맵에 3 x 3 특성 맵을 적용하면 3 x 3 출력 특성 맵이 나옴\n",
        "    - 동일한 높이와 너비를 가진 출력 특성 맵을 얻고 싶다면 padding을 사용\n",
        "    - padding = 'same' default 값은 valid(사용안함)\n",
        "  - 스트라이드(stride) 사용 여부\n",
        "    - 지금까지 합성곱에 대한 설명은 합성곱 윈도우의 중앙 타일이 연속적으로 지나간다고 가정\n",
        "    - 두번의 연속적인 윈도우 사이의 거리가 스트라이드라고 불리는 합성곱의 파리미터\n",
        "    - 몇칸씩 이동시키냐\n",
        "    - 스트라이드 2를 사용했다는 것은 특성 맵의 너비와 높이가 2의 배수로 다운샘플링되었다는 뜻입니다."
      ],
      "metadata": {
        "id": "qiFvUAwxSdDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최대 풀링 연산(MaxPooLing)\n",
        "- 스트라이드 합성곱과 매우 비슷하게 강제적으로 특생맵을 다운샘플링하는 것이 최대 풀링의 역할\n",
        "- 입력 특성 맵에서 윈도우에 맞는 패치를 추출하고 각 채널별로 최댓값을 출력\n",
        "- 합성곱과 개념적으로 비슷하지만 추출한 패치에 학습된 선형 변환(합성곱 커널)을 적용하는 대신 하드코딩된 최댓값 추출 연산을 사용\n",
        "- 합성곱과 가장 큰 차이점은 최대 풀리은 보통 2 x 2 윈도우와 스트라이드 2를 사용하여 특성맵을 절반 크기로 다운샘플링 한다는 것입니다. 이에 반해 합성곱은 전형적으로 3 x 3 윈도우 스트라이드 1을 사용합니다.\n",
        "- 최대 풀링 층을 사용하지 않을 때 문제\n",
        "  - 특성의 공간적 계층 구조를 학습하는데 도움이 되지 않습니다.\n",
        "    - 세 번째 층의 3 x 3 윈도우는 초기 입력의 7 x 7 윈도우 영역에 대한 정보만 담고 있습니다.\n",
        "    - 컨브넷에 의해 학습된 고수준 패턴은 초기 입력에 관한 정보가 아주 적어 숫자 분류를 학습하기에 충분하지 않을 것입니다.\n",
        "  - 최종 특성 맵은 22 x 22 x 64 = 30,967개의 원소를 가집니다.\n",
        "    - 너무 많은 원소는 많은 가중치로 인해 심각한 과대적합이 발생할 것입니다."
      ],
      "metadata": {
        "id": "szaOY90xdqbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련하기\n",
        "## 작은 데이터셋 문제에서 딥러닝의 타당성\n",
        "- 딥러닝의 근본적인 특징은 훈련 데이터에서 특성 공학의 수작업 없이 흥미로운 특성을 찾을 수 있는 것\n",
        "  - 위와 같이 하기위해서는 훈련 샘플이 많아야함(특히 이미지 같은 고차원 문제)\n",
        "  - 하지만 많은 샘플이 의미하는 것은 상대적이다. 훈련하는 네트워크의 크기와 깊이는 상대적입니다.\n",
        "   - 복잡한 문제를 푸는 컨브넷을 수십 개의 샘플만 사용해서 훈련하는 것은 불가능하지만 모델이 작고 규제가 잘 되어 있으며 간단한 작업이라면 수백 개의 샘플로도 충분히 가능 합니다.\n",
        "   - 이미지는 IamgeNet에서 사전 훈련된 모델을 많이 사용\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "YFP3SkeYn6WF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 내려받기"
      ],
      "metadata": {
        "id": "RC36tBEWqFFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!unzip -qq \"/content/drive/MyDrive/deeplearning_study/data/cats_and_dogs/train.zip\"\n",
        "!unzip -qq \"/content/drive/MyDrive/deeplearning_study/data/cats_and_dogs/test1.zip\""
      ],
      "metadata": {
        "id": "yTIOkdknSOQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip하고 폴더 만들고 옮기기\n",
        "import os, shutil\n",
        "original_dataset_dir = '/content/train'\n",
        "\n",
        "!mkdir cats_and_dogs_small\n",
        "\n",
        "base_dir = '/content/cats_and_dogs_small'"
      ],
      "metadata": {
        "id": "la9N1yhNtKU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# directory 생성\n",
        "## 훈련,검증,테스트 분할을 위한 directory\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir,'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "## 훈련용,검증용,테스트용 고양이 강아지 사진 directory\n",
        "### 훈련용 고양이\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "os.mkdir(train_cats_dir)\n",
        "\n",
        "### 훈련용 강아지\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "os.mkdir(train_dogs_dir)\n",
        "\n",
        "### 검증용 고양이\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "os.mkdir(validation_cats_dir)\n",
        "\n",
        "### 검증용 강아지\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "os.mkdir(validation_dogs_dir)\n",
        "\n",
        "### 테스트용 고양이\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "os.mkdir(test_cats_dir)\n",
        "\n",
        "### 테스트용 강아지\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "os.mkdir(test_dogs_dir)\n",
        "\n",
        "### 처음 1,000개의 고양이 이미지를 train_cats_dir 복사\n",
        "fnames = [f'cat.{i}.jpg' for i in range(1000)]\n",
        "for fname in fnames:\n",
        "  src = os.path.join(original_dataset_dir,fname)\n",
        "  dst = os.path.join(train_cats_dir,fname)\n",
        "  shutil.copyfile(src,dst)\n",
        "\n",
        "### 다음 500개의 고양이 이미지를 validation_cats_dir 복사\n",
        "fnames = [f'cat.{i}.jpg' for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "  src = os.path.join(original_dataset_dir,fname)\n",
        "  dst = os.path.join(validation_cats_dir,fname)\n",
        "  shutil.copyfile(src,dst)\n",
        "\n",
        "### 다음 500개의 고양이 이미지를 test_cats_dir에 복사\n",
        "fnames = [f'cat.{i}.jpg' for i in range(1500,2000)]\n",
        "for fname in fnames:\n",
        "  src = os.path.join(original_dataset_dir,fname)\n",
        "  dst = os.path.join(test_cats_dir,fname)\n",
        "  shutil.copyfile(src,dst)\n",
        "\n",
        "### 처음 1,000개의 강아지 이미지를 train_dogs_dir 복사\n",
        "fnames = [f'dog.{i}.jpg' for i in range(1000)]\n",
        "for fname in fnames:\n",
        "  src = os.path.join(original_dataset_dir,fname)\n",
        "  dst = os.path.join(train_dogs_dir,fname)\n",
        "  shutil.copyfile(src,dst)\n",
        "\n",
        "### 다음 500개의 강아지 이미지를 validation_cats_dir 복사\n",
        "fnames = [f'dog.{i}.jpg' for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "  src = os.path.join(original_dataset_dir,fname)\n",
        "  dst = os.path.join(validation_dogs_dir,fname)\n",
        "  shutil.copyfile(src,dst)\n",
        "\n",
        "### 다음 500개의 강아지 이미지를 test_cats_dir에 복사\n",
        "fnames = [f'dog.{i}.jpg' for i in range(1500,2000)]\n",
        "for fname in fnames:\n",
        "  src = os.path.join(original_dataset_dir,fname)\n",
        "  dst = os.path.join(test_dogs_dir,fname)\n",
        "  shutil.copyfile(src,dst)"
      ],
      "metadata": {
        "id": "jPYtnOa6t0cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(train_cats_dir)))\n",
        "print(len(os.listdir(train_dogs_dir)))\n",
        "print(len(os.listdir(validation_cats_dir)))\n",
        "print(len(os.listdir(validation_dogs_dir)))\n",
        "print(len(os.listdir(test_cats_dir)))\n",
        "print(len(os.listdir(test_dogs_dir)))"
      ],
      "metadata": {
        "id": "XO_N0B8cxfTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 네트워크 구성\n",
        "- Conv2D(relu 활성화 함수 사용, MaxPooling2D 층을 번갈아 쌓은 컨브넷 생성"
      ],
      "metadata": {
        "id": "1Cl6xve5xxO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 강아지 vs 고양이 분류를 위한 소규모 컨브넷 만들기\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3), activation = 'relu',input_shape = (150,150,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512,activation='relu'))\n",
        "model.add(layers.Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "i5AoXq_7yDN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련 설정\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = optimizers.RMSprop(lr = 1e-4),\n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "pkCpF721zXos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리\n",
        "- 데이터는 네트워크에 주입되기 전에 부동 소수 타입의 텐서로 적절하게 전처리되어 있어야 합니다.\n",
        "- 과정\n",
        "  1. 사진 파일을 읽습니다.\n",
        "  2. JPEG 콘텐츠를 RGB 픽셀 값으로 디코딩합니다.\n",
        "  3. 그다음 부동 소수 타입의 텐서로 변환\n",
        "  4. 픽셀 값(0에서 255사이)의 스케일을 [0,1] 사이로 조정합니다(신경망은 작은 입력 값을 선호합니다.)\n",
        "- 케라스 이미지 tool\n",
        "  - keras.preprocessing.image\n",
        "    -ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "_GKFYkYm0FB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageDataGenerator를 사용하여 디렉터리에서 이미지 읽기\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size = (150,150),\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size = (150,150),\n",
        "                                                        batch_size = 20,\n",
        "                                                        class_mode = 'binary')"
      ],
      "metadata": {
        "id": "xlkcxpO60Ejv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data_batch,labels_batch in train_generator:\n",
        "  print('배치 데이터 크기 : ',data_batch.shape)\n",
        "  print('배치 레이블 크기 : ',labels_batch.shape)\n",
        "  break\n"
      ],
      "metadata": {
        "id": "Uhes3JF0z227"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 배치 제너레이터를 사용하여 모델 훈련하기\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch = 100, # 첫 번째 매개변수로 입력과 타깃의 배치를 끝없이 반환 하기 떄문에 steps_per_epoch를 사용\n",
        "                              epochs = 30,\n",
        "                              validation_data = validation_generator,\n",
        "                              validation_steps = 40)\n",
        "\n",
        "## 항상 모델은 저장하기\n",
        "model.save('cats_and_dogs_small_1.h5')"
      ],
      "metadata": {
        "id": "lw9zL6ZQ58Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/deeplearning_study/data/cats_and_dogs/cats_and_dogs_small_1.h5')"
      ],
      "metadata": {
        "id": "TSkccFEIX9bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련의 정확도와 손실 그래프 그리기\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epoch = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epoch, acc, 'bo', label = 'Training acc')\n",
        "plt.plot(epoch, val_acc, 'b', label = 'Validation acc')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epoch, loss, 'bo', label = 'Training loss')\n",
        "plt.plot(epoch, val_loss, 'b', label = 'Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q6xTZFD366hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 증식 사용하기\n",
        "- 과대적합은 학습할 샘플이 너무 적어 새로운 데이터에 일반화할 수 있는 모델을 훈련시킬 수 없기 때문에 발생.\n",
        "- 무한히 많은 데이터가 주어지면 데이터 분포의 모든 가능한 측면을 모델이 학습할 수 있을 것입니다.\n",
        "- 데이터 증식은 기존 훈련 샘플로부터 더 많은 훈련 데이터를 생성하는 방법\n",
        "- 이 방법은 그럴듯한 이미지를 생성하도록 여러가지 랜덤 변환을 적용하여 샘플을 늘립니다. 훈련할 때 모델이 정확히 같은 데이터를 두 번 만나지 않도록 하는 것이 목표"
      ],
      "metadata": {
        "id": "A2tdx5kjUCyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageDataGenerator를 사용하여 데이터 증식 설정\n",
        "datagen = ImageDataGenerator(rotation_range = 20,\n",
        "                             width_shift_range = 0.1,\n",
        "                             height_shift_range = 0.1,\n",
        "                             shear_range = 0.1,\n",
        "                             zoom_range = 0.1,\n",
        "                             horizontal_flip = True,\n",
        "                             fill_mode = 'nearest')"
      ],
      "metadata": {
        "id": "N7KV2JJwOHDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤하게 증식된 이미지 확인\n",
        "from tensorflow.keras.preprocessing import image  # 이미지 전처리 유틸리티 모듈\n",
        "\n",
        "fnames = sorted([os.path.join(train_cats_dir,fname) for fname in os.listdir(train_cats_dir)])\n",
        "\n",
        "img_path = fnames[3] # 증식할 이미지 선택\n",
        "\n",
        "img = image.load_img(img_path,target_size=(150,150))\n",
        "\n",
        "x = image.img_to_array(img) # (150,150,3) 크기의 넘파이 배열로 변환\n",
        "x = x.reshape((1,) + x.shape) # (1,150,150,3) 크기로 변환\n",
        "\n",
        "# 랜덤하게 변환된 이미지 배치를 생성, 무한 반복 되기때문에 어느 지점에서 중지해야합니다.\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size = 1):\n",
        "  plt.figure(i)\n",
        "  imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "  i +=1\n",
        "  if i % 4 == 0:\n",
        "    break\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ss3FaFxQVlGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 드롭아웃(->과대적합을 억제하기 위해 완전 연결 분류기)을 포함한 새로운 컨브넷 정의하기\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (150,150,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512,activation = 'relu'))\n",
        "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = optimizers.RMSprop(lr=1e-4),\n",
        "              metrics = ['acc'])"
      ],
      "metadata": {
        "id": "BHpnMTElYHmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iKu87P76b7U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 증식 제너레이터를 사용하여 컨브넷 훈련하기"
      ],
      "metadata": {
        "id": "Eo7TGfPgZcnU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}